> library(faraway)  #this command brings in a library of regression functions
> 
> #Use the QUASARS dataset from the textbook to examine residuals (data - fit)
> 
> #read in the data which is in a csv file
> quasars <- read.csv(file="C:/Users/jmard/Desktop/RegressionMethodsSpring2020/Lecture 03 04FEB2020/QUASAR.csv",header = TRUE)
> 
> # n=25 observations on 5 independent variables (covariates) 
> # REDSHIFT (x1) LINEFLUX(x2) LUMINOSITY(x3) AB1450(x4) ABSMAG(x5) 
> # and a response RFEWIDTH (y)
> quasars
   QUASAR REDSHIFT LINEFLUX LUMINOSITY AB1450 ABSMAG RFEWIDTH
1       1     2.81   -13.48      45.29  19.50 -26.27      117
2       2     3.07   -13.73      45.13  19.65 -26.26       82
3       3     3.45   -13.87      45.11  18.93 -27.17       33
4       4     3.19   -13.27      45.63  18.59 -27.39       92
5       5     3.07   -13.56      45.30  19.59 -26.32      114
6       6     4.15   -13.95      45.20  19.42 -26.97       50
7       7     3.26   -13.83      45.08  19.18 -26.83       43
8       8     2.81   -13.50      45.27  20.41 -25.36      259
9       9     3.83   -13.66      45.41  18.93 -27.34       58
10     10     3.32   -13.71      45.23  20.00 -26.04      126
11     11     2.81   -13.50      45.27  18.45 -27.32       42
12     12     4.40   -13.96      45.25  20.55 -25.94      146
13     13     3.45   -13.91      45.07  20.45 -25.65      124
14     14     3.70   -13.85      45.19  19.70 -26.51       75
15     15     3.07   -13.67      45.19  19.54 -26.37       85
16     16     4.34   -13.93      45.27  20.17 -26.29      109
17     17     3.00   -13.75      45.08  19.30 -26.58       55
18     18     3.88   -14.17      44.92  20.68 -25.61       91
19     19     3.07   -13.92      44.94  20.51 -25.41      116
20     20     4.08   -14.28      44.86  20.70 -25.67       75
21     21     3.62   -13.82      45.20  19.45 -26.73       63
22     22     3.07   -14.08      44.78  19.90 -26.02       46
23     23     2.94   -13.82      44.99  19.49 -26.35       55
24     24     3.20   -14.15      44.75  20.89 -25.09       99
25     25     3.24   -13.74      45.17  19.17 -26.83       53
> 
> #Peform a multiple regression using the quasar data
> lmod <- lm(RFEWIDTH ~ REDSHIFT+LINEFLUX+LUMINOSITY+AB1450,data=quasars)
> 
> summary(lmod)

Call:
lm(formula = RFEWIDTH ~ REDSHIFT + LINEFLUX + LUMINOSITY + AB1450, 
    data = quasars)

Residuals:
    Min      1Q  Median      3Q     Max 
-19.757  -9.039  -2.250   1.756  48.628 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 21087.951  18553.161   1.137   0.2691    
REDSHIFT      108.451     88.740   1.222   0.2359    
LINEFLUX      557.910    315.990   1.766   0.0927 .  
LUMINOSITY   -340.166    320.763  -1.060   0.3016    
AB1450         85.681      6.273  13.658 1.34e-11 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 15.42 on 20 degrees of freedom
Multiple R-squared:  0.9118,    Adjusted R-squared:  0.8942 
F-statistic: 51.72 on 4 and 20 DF,  p-value: 2.867e-10

> anova(lmod)
Analysis of Variance Table

Response: RFEWIDTH
           Df Sum Sq Mean Sq  F value    Pr(>F)    
REDSHIFT    1    274     274   1.1511  0.296104    
LINEFLUX    1   2218    2218   9.3327  0.006251 ** 
LUMINOSITY  1   2342    2342   9.8566  0.005160 ** 
AB1450      1  44329   44329 186.5398 1.337e-11 ***
Residuals  20   4753     238                       
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> 
> windows(7,7)
> #now save the plots in a pdf file
>  pdf(file="C:/users/jmard/Desktop/RegressionMethodsSpring2020/Lecture 06 25FEB2020/Diag_QUASAR_R_out.pdf")
> 
> #what do we look for in checking error assumptions
> par(mfrow=c(3,3))
> n <- 50
> for(i in 1:9) {x <- runif(n) ; plot(x,rnorm(n))}  #Constant variance
> 
> for(i in 1:9) {x <- runif(n) ; plot(x,x*rnorm(n))}  #Strong nonconstant variance
> 
> for(i in 1:9) {x <- runif(n) ; plot(x,sqrt((x))*rnorm(n))}  #Mild nonconstant variance
> 
> for(i in 1:9) {x <- runif(n) ; plot(x,cos(x*pi/25)+rnorm(n,sd=1))} #Nonlinearity
> par(mfrow=c(1,1))
> 
> #checking for constant variance and nonlinear assumptions
> plot(fitted(lmod),residuals(lmod),xlab="Fitted",ylab="Residuals")
> abline(h=0)  #if you see patterns then suspect nonlinearity
> 
> #plot the square root of the absolute value of the residuals
> # to examine the constant variance assumption more closely
> plot(fitted(lmod),sqrt(abs(residuals(lmod))),xlab="Fitted",ylab="sqrt of |ei|")
> 
> #plot residuals against all the X's in the model
> #powers of X should be added to the model?
> plot(quasars$REDSHIFT,residuals(lmod),xlab="REDSHIFT",ylab="Residuals")  #plot residuals against all the X's in the model
> abline(h=0)  #in this case OK - need to generate this plot for the other X's in the model
> 
> #plot residuals against X's not in the model for potential inclusion?
> plot(quasars$AB1450,residuals(lmod),xlab="ABSMAG",ylab="Residuals")  #plot residuals against potential X's not in the model
> abline(h=0)
> 
> abs(residuals(lmod))
         1          2          3          4          5          6          7          8          9         10         11         12         13 
19.7571979 10.7556039 32.0274725  9.5035689 10.6312697  6.3758631  8.6915197 48.6279584  0.7047511  0.9983158  0.4372401  1.0309725  1.5020914 
        14         15         16         17         18         19         20         21         22         23         24         25 
 3.0045787 11.3953482  6.8371724  6.0257677  3.8066865  9.0698696  2.2503290  1.7561053  8.0346376  7.3593223  9.0394627  2.1203619 
> which.max(abs(residuals(lmod)))  #check for outliers
8 
8 
> 
> #Checking for normality
> #The confidence intervals and tests of hypotheses we conduct assume errors are normal(0,sigma^2)
> #Use Q-Q plots - sort residuals smallest to largest and plot residual against Finverse(i/n+1)
> #where Finverse in the inverse of the standard normal distribution function
> 
> qqnorm(residuals(lmod),ylab="Residuals",main="Q-Q plot")
> qqline(residuals(lmod))
> 
> 
> #Examples of Q-Q plots from various distributions
> par(mfrow=c(3,3))
> n <- 50
> 
> for(i in 1:9) {x <- rnorm(n); qqnorm(x); qqline(x)}  #normal distribution
> 
> for(i in 1:9) {x <- exp(rnorm(n)); qqnorm(x); qqline(x)}  #log-normal which is skewed to right distribution
> 
> for(i in 1:9) {x <- rcauchy(n); qqnorm(x); qqline(x)}  #Cauchy which is thick tailed but symmetric distribution
> 
> for(i in 1:9) {x <- runif(n); qqnorm(x); qqline(x)} #uniform - short-tailed distribution
> par(mfrow=c(1,1))
> 
> #A formal test for normality:  Shapiro-Wilk test
> #This test is sensitive to slight depatures from normality - are of limited use in practice
> # H0: residuals are normally distributed
> 
> shapiro.test(residuals(lmod))

        Shapiro-Wilk normality test

data:  residuals(lmod)
W = 0.77909, p-value = 0.0001039

> 
> sd(residuals(lmod))
[1] 14.07239
> 
> ks.test(x=residuals(lmod),y="pnorm",0,15) #One-sample Kolmogorov-Smirnov test

        One-sample Kolmogorov-Smirnov test

data:  residuals(lmod)
D = 0.24379, p-value = 0.08571
alternative hypothesis: two-sided

> #normal with mean=0 and sigma=15?  #has some issues with inflated TYPE II error
> 
> #Introduction to the concept of leverage and influence in Simple Linear Regression (one X)
> #Leverage measures how far an observation is from Xbar
> #Influence measures impact on estimates
> 
> #Test for detecting violation of normality assumption using olsrr package
> require(olsrr)
Loading required package: olsrr
Registered S3 methods overwritten by 'car':
  method                          from
  influence.merMod                lme4
  cooks.distance.influence.merMod lme4
  dfbeta.influence.merMod         lme4
  dfbetas.influence.merMod        lme4

Attaching package: ‘olsrr’

The following object is masked from ‘package:faraway’:

    hsb

The following object is masked from ‘package:datasets’:

    rivers

> ols_test_normality(lmod)
-----------------------------------------------
       Test             Statistic       pvalue  
-----------------------------------------------
Shapiro-Wilk              0.7791          1e-04 
Kolmogorov-Smirnov        0.2401         0.0941 
Cramer-von Mises          2.1961         0.0000 
Anderson-Darling          1.7756          1e-04 
-----------------------------------------------
> 
> set.seed(123)
> 
> #example of a point with no leverage but influence
> testdata <- data.frame(x=1:10,y=1:10+rnorm(10))
> lmod <- lm(y ~ x, testdata)
> p1 <- c(5.5,12)
> lmod1 <- lm(y ~ x, rbind(testdata, p1))
> plot(y ~ x, rbind(testdata, p1))
> points(5.5,12,pch=4,cex=2)
> abline(lmod)
> abline(lmod1, lty=2)
> 
> #example of a point with leverage but little influence
> p2 <- c(15,15.1)
> lmod2 <- lm(y ~ x, rbind(testdata, p2))
> plot(y ~ x, rbind(testdata, p2))
> points(15,15.1,pch=4,cex=2)
> abline(lmod)
> abline(lmod2,lty=2)
> 
> #example of a point with leverage and influence
> p3 <- c(15,5.1)
> lmod3 <- lm(y ~ x, rbind(testdata, p3))
> plot(y ~ x, rbind(testdata, p3))
> points(15,5.1,pch=4,cex=2)
> abline(lmod)
> abline(lmod3,lty=2)
> 
> #Yhat=XBhat which is X(X'X)-1X'Y which is HY  Yhat is a linear combination of Y's
> #The HAT matrix is H=X(X'X)-1X'  which is nxn
> #hii – standardized measure of the distance of the ith observation
> #from the center of the x-space.
> 
> x <- model.matrix( ~ REDSHIFT+LINEFLUX+LUMINOSITY+AB1450,quasars)
> head(x,10L)
   (Intercept) REDSHIFT LINEFLUX LUMINOSITY AB1450
1            1     2.81   -13.48      45.29  19.50
2            1     3.07   -13.73      45.13  19.65
3            1     3.45   -13.87      45.11  18.93
4            1     3.19   -13.27      45.63  18.59
5            1     3.07   -13.56      45.30  19.59
6            1     4.15   -13.95      45.20  19.42
7            1     3.26   -13.83      45.08  19.18
8            1     2.81   -13.50      45.27  20.41
9            1     3.83   -13.66      45.41  18.93
10           1     3.32   -13.71      45.23  20.00
> xtxi <- solve(t(x) %*% x)  #compute XPX inverse
> xtxi
              (Intercept)     REDSHIFT      LINEFLUX    LUMINOSITY      AB1450
(Intercept) 1448501.99649 6903.9753965 24634.4471761 -25041.294210 -72.0171569
REDSHIFT       6903.97540   33.1375224   117.6149218   -119.314749  -0.3327908
LINEFLUX      24634.44718  117.6149218   420.1753163   -425.648813  -0.9186099
LUMINOSITY   -25041.29421 -119.3147491  -425.6488130    432.962942   1.2670511
AB1450          -72.01716   -0.3327908    -0.9186099      1.267051   0.1656079
> H=(x %*% xtxi %*% t(x)) #H
> head(H)
            1           2            3           4            5           6            7           8           9          10         11
1  0.21630662  0.06116810 -0.099760450  0.06840336  0.094307944 -0.01093020  0.021704943  0.25273522 0.001919231  0.01020419 0.16519717
2  0.06116810  0.06192272  0.045541983  0.06042924  0.064580349 -0.01852715  0.041240792  0.06979648 0.010500124  0.06258634 0.05038830
3 -0.09976045  0.04554198  0.257817599  0.10513460  0.009688768  0.06809985  0.116363174 -0.21521076 0.111607117  0.05321159 0.04455139
4  0.06840336  0.06042924  0.105134601  0.37790523  0.159565676 -0.01032615  0.003587326  0.06160520 0.175338579  0.16629290 0.05104494
5  0.09430794  0.06458035  0.009688768  0.15956568  0.113920247 -0.04343199 -0.001213661  0.14195798 0.038810019  0.11447799 0.02592465
6 -0.01093020 -0.01852715  0.068099849 -0.01032615 -0.043431991  0.22994411  0.082039521 -0.09541755 0.145337466 -0.06586888 0.09433786
            12          13          14          15            16          17          18          19           20          21           22
1  0.071091494 -0.04030194 -0.02749607  0.06889746  0.0293790164  0.10084763 -0.06243652  0.05954400 -0.068239373 -0.03893305 -0.001412525
2 -0.032370682  0.05982810  0.02870753  0.06198116 -0.0248331216  0.05073648  0.02176804  0.06680423  0.002154371  0.03388889  0.057703455
3 -0.135125807  0.06667649  0.09457304  0.04465984 -0.0536889045  0.03670772  0.04598400 -0.01947662  0.038369660  0.13329893  0.102596065
4 -0.039912090  0.08992190  0.09116074  0.09494000  0.0096120030 -0.02539331 -0.07073631 -0.04609803 -0.146633728  0.11202504 -0.142993772
5 -0.001696239  0.08722863  0.03944615  0.07673602  0.0003343093  0.01410845 -0.00267274  0.05637841 -0.048852244  0.03923558 -0.029514650
6  0.194874686 -0.07183066  0.06246340 -0.01871774  0.1907174814  0.05302680  0.04961190 -0.06746013  0.117331410  0.06133394  0.020503389
            23            24         25
1  0.115757371 -0.0004095901 0.01245596
2  0.051176968  0.0627790106 0.05004829
3  0.010743843  0.0109958145 0.12664108
4 -0.092354052 -0.1403978849 0.08787858
5 -0.003731793  0.0156511312 0.03876102
6  0.052936066 -0.0612248761 0.04117747
> 
> if (FALSE)
+ {"
+ Should an influential point be discarded?
+ Yes, if
+ –there is an error in recording a measured value;
+ –the sample point is invalid; or,
+ –the observation is not part of the population that was intended to be sampled
+ No, if
+ –the influential point is a valid observation.
+ 
+ Robust estimation techniques
+ –These techniques offer an alternative to deleting an influential observation.
+ –Observations are retained but downweighted in proportion to residual magnitude or influence.
+ "}
> 
> ##------------------------------------------------------------------##
> 
> dev.off()

